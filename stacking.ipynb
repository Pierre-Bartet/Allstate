{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's stack our xgboost and keras model together !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost\n",
    "import pandas as pd\n",
    "from sklearn import utils\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"data/train.csv\")\n",
    "data_train.drop(\"id\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"data/test.csv\")\n",
    "ids = data_test.values[:, 0]\n",
    "data_test.drop(\"id\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transform categorical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whole_categ_data = pd.concat( [ data_train.iloc[:,0:116], data_test.iloc[:,0:116] ], ignore_index=True ).iloc[:, 0:116]\n",
    "\n",
    "from collections import defaultdict\n",
    "label_encoder = defaultdict( preprocessing.LabelEncoder )\n",
    "whole_categ_data = whole_categ_data.apply(lambda x: label_encoder[x.name].fit_transform(x) )\n",
    "\n",
    "data_train.iloc[:, 0:116] = data_train.iloc[:,0:116].apply(lambda x: label_encoder[x.name].transform(x) )\n",
    "data_test.iloc[:, 0:116] = data_test.iloc[:,0:116].apply(lambda x: label_encoder[x.name].transform(x) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extract the features and target, then shuffle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data_train.values[:, :-1]\n",
    "y = data_train.values[:, -1]\n",
    "\n",
    "X, y = utils.shuffle(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 0 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Log transform the target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def target_transform(y):\n",
    "    return np.log(y)\n",
    "\n",
    "def target_inv_transform(y):\n",
    "    return np.exp(y)\n",
    "\n",
    "trans_y = target_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Turn features and targets into xgb matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = xgboost.DMatrix(X, trans_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Take best parameters from the xgboost notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def convert_params(params):    \n",
    "    converted = copy.deepcopy(params)\n",
    "    converted['max_depth'] = int(converted['max_depth'])\n",
    "    converted['min_child_weight'] = int(converted['min_child_weight'])\n",
    "    converted['learning_rate'] = converted.pop('eta')\n",
    "    \n",
    "    return converted\n",
    "\n",
    "#Best parameters in our phase space :\n",
    "best = {'colsample_bytree': 0.55, 'min_child_weight': 186.0, 'subsample': 0.8500000000000001, 'eta': 0.025, 'max_depth': 12.0, 'gamma': 0.8500000000000001}\n",
    "best = convert_params(best)\n",
    "best['n_estimators'] = 800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_model = xgboost.XGBRegressor(**best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make cross validated predictions (and look at the score as a sanity check):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb cv score : 1136.33455648\n"
     ]
    }
   ],
   "source": [
    "xgb_pred = cross_val_predict(xgb_model, X, trans_y, cv = 5)\n",
    "print 'xgb cv score :', metrics.mean_absolute_error(  target_inv_transform(xgb_pred),\n",
    "                                                      y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One hot encode the categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<type 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoder = preprocessing.OneHotEncoder( sparse = False )\n",
    "one_hot_encoder.fit( whole_categ_data.values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = one_hot_encoder.transform( X[:,:116] )\n",
    "hot_X = np.hstack( ( labels ,  X[:,116:] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Neural network builder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "def create_model(params):\n",
    "    nn = Sequential()\n",
    "\n",
    "    #Layers\n",
    "    for i in xrange( params['n_layers'] ):\n",
    "        if i == 0 : #Input layer\n",
    "            nn.add( Dense( params['n_units'] , input_dim=hot_X.shape[1]) )\n",
    "        else: #Hidden layers\n",
    "            nn.add( Dense( params['n_units']) )\n",
    "            \n",
    "        if( params['activation'] == 'prelu' ) : \n",
    "            nn.add( PReLU() )\n",
    "        elif( params['activation'] == 'relu' ):\n",
    "            nn.add( Activation( 'relu' ) )   \n",
    "        if( params['dropout'] != 0.0 ) : nn.add( Dropout(params['dropout']) )\n",
    "        \n",
    "    #Output\n",
    "    nn.add( Dense(1) )\n",
    "    nn.compile(loss='mae', optimizer='adam')\n",
    "    \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Take best parameters from the keras notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras cv score : 1145.12472784\n"
     ]
    }
   ],
   "source": [
    "best = {'n_units': 1024, 'activation': 'prelu', 'n_layers': 2, 'dropout': 0.61}\n",
    "keras_model = KerasRegressor( build_fn = lambda : create_model(best), nb_epoch=30, batch_size=128, verbose=0 )\n",
    "\n",
    "keras_pred = cross_val_predict(keras_model, hot_X, y, cv = 5)\n",
    "print 'keras cv score :', metrics.mean_absolute_error( keras_pred, y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mae(estimator, X, y):\n",
    "    return metrics.mean_absolute_error( target_inv_transform(estimator.predict(X)),\n",
    "                                        target_inv_transform(y) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fit a linear regression using our two cv predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score : 1131.16168671 +- 2.03177055231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "features = np.hstack( ( xgb_pred[:, None], target_transform( keras_pred[:, None] ) ) )\n",
    "stack_model = LinearRegression(fit_intercept = False)\n",
    "\n",
    "scores = cross_val_score(stack_model, features, trans_y, cv=5, scoring = mae)\n",
    "print 'Cross validation score :', scores.mean(), '+-', scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The cv score is better than each our single model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.75529674  0.24461054]\n"
     ]
    }
   ],
   "source": [
    "stack_model.fit(features, trans_y)\n",
    "print stack_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As expected since it is our best single model, the xgboost model has a greater weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the single models test predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_test_pred = pd.read_csv(\"xgboost_predictions.csv\").values[:, 1:]\n",
    "keras_test_pred = pd.read_csv(\"keras_predictions.csv\").values[:, 1:]\n",
    "\n",
    "test_features = np.hstack( ( target_transform( xgb_test_pred ), target_transform( keras_test_pred ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Stack them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacker_predictions = target_inv_transform( stack_model.predict( test_features ) )\n",
    "\n",
    "submission = pd.DataFrame( {'id': ids, 'loss': stacker_predictions } )\n",
    "submission.to_csv('stacker_predictions.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our MAE score on kaggle (after the end of the competition) is 1125.8 with this model, which is our best results so far!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
